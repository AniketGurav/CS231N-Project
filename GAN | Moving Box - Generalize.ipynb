{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "from util.parser import *\n",
    "from util.img_kit import *\n",
    "from util.notebook_display import *\n",
    "from util.numeric_ops import *\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "from os import walk\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0) # set default size of plots\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    return session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect an ensemble of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_imgs(file):\n",
    "    data = np.load(file)\n",
    "    imgs, info = data['imgs'], data['info']\n",
    "    print(info)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"data/moving-box/processed\"\n",
    "data_collection = [p[2] for p in walk(folder)][0]\n",
    "data_collection = filter_files(data_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flipped_frames(frames):\n",
    "    return frames[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_data(data):\n",
    "    return data + [flipped_frames(x) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dim': (50, 32, 32), 'images:': 'triangle'}\n",
      "{'dim': (56, 32, 32), 'images:': 'rectangle'}\n",
      "{'dim': (56, 32, 32), 'images:': 'trangle-vertical'}\n",
      "{'dim': (56, 32, 32), 'images:': 'circle-diagnal'}\n",
      "{'dim': (56, 32, 32), 'images:': 'square-diagnal-2'}\n",
      "{'dim': (56, 32, 32), 'images:': 'rectangle'}\n",
      "{'dim': (56, 32, 32), 'images:': 'square-vertical-2'}\n",
      "{'dim': (56, 32, 32), 'images:': 'trangle-vertical-3'}\n",
      "{'dim': (56, 32, 32), 'images:': 'trangle-horizontal'}\n",
      "{'dim': (56, 32, 32), 'images:': 'square-vertical-3'}\n",
      "{'dim': (56, 32, 32), 'images:': 'rectangle'}\n",
      "{'dim': (56, 32, 32), 'images:': 'trangle-vertical-2'}\n",
      "{'dim': (56, 32, 32), 'images:': 'rectangle'}\n",
      "{'dim': (14, 32, 32), 'images:': 'moving box uniform'}\n",
      "{'dim': (56, 32, 32), 'images:': 'circle'}\n",
      "{'dim': (56, 32, 32), 'images:': 'rectangle'}\n",
      "{'dim': (56, 32, 32), 'images:': 'rectangle'}\n",
      "{'dim': (56, 32, 32), 'images:': 'rectangle'}\n",
      "{'dim': (56, 32, 32), 'images:': 'circle-diagnal-2'}\n",
      "{'dim': (56, 32, 32), 'images:': 'square-vertical'}\n",
      "{'dim': (56, 32, 32), 'images:': 'square-diagnal'}\n",
      "\n",
      "After Augmentation: img_collections has 21 collections\n"
     ]
    }
   ],
   "source": [
    "img_collections = [load_imgs(os.path.join(folder, f)) for f in data_collection]\n",
    "# img_collections = augment_data(img_collections)\n",
    "num_per_collection = [x.shape[0] for x in img_collections]\n",
    "n_collection = len(img_collections)\n",
    "print()\n",
    "print(\"After Augmentation: img_collections has {} collections\".format(len(img_collections)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_dev(data, train_ratio = 0.8):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        data: np array\n",
    "    Return:\n",
    "        train_ind: index of training data\n",
    "        val_ind:   index of validation data\n",
    "    \"\"\"\n",
    "    n = data.shape[0]\n",
    "    num_train = int(n*train_ratio)\n",
    "    train_ind = np.random.choice(range(n), num_train, replace=False)\n",
    "    train_ind.sort()\n",
    "    val_ind = list(set(range(n)) - set(train_ind))\n",
    "    val_ind.sort()\n",
    "    return train_ind, val_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ind_collection, val_ind_collection = zip(*[split_train_dev(x) for x in img_collections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample(batch_size = 8, train=True, gap = 1):\n",
    "    # get average number of training for each class\n",
    "    avg_num_per_class = int(np.ceil(batch_size/n_collection))\n",
    "    # before-index for each class\n",
    "    before_ind = []\n",
    "    for i in range(n_collection):\n",
    "        data = train_ind_collection[i] if train else val_ind_collection[i]\n",
    "        try:\n",
    "            s = np.random.choice(list(filter(lambda x:x<num_per_collection[i]-gap-1, data)),avg_num_per_class, replace=False)\n",
    "            before_ind.append(s)\n",
    "        except:\n",
    "            before_ind.append(np.array([]))\n",
    "    # after-index for each class\n",
    "    after_ind = [x+gap+1 for x in before_ind]\n",
    "    # mid-index for each class\n",
    "    mid_ind = [x+(gap+1)//2 for x in before_ind]\n",
    "    \n",
    "    selected_classed = [i for i in range(n_collection) if before_ind[i].shape[0]>0]\n",
    "    before_imgs = np.concatenate([img_collections[i][before_ind[i]] for i in selected_classed], axis = 0)\n",
    "    after_imgs = np.concatenate([img_collections[i][after_ind[i]] for i in selected_classed], axis = 0)\n",
    "    mid_imgs = np.concatenate([img_collections[i][mid_ind[i]] for i in selected_classed], axis = 0)\n",
    "    \n",
    "    clipped = np.random.choice(range(before_imgs.shape[0]), batch_size, replace=False)\n",
    "    before_imgs = before_imgs[clipped]\n",
    "    mid_imgs = mid_imgs[clipped]\n",
    "    after_imgs = after_imgs[clipped]\n",
    "    return (before_imgs, after_imgs), mid_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_train(batch_size = 8, gap = 1):\n",
    "    return sample(batch_size)\n",
    "def sample_dev(batch_size = 8, gap = 1):\n",
    "    return sample(batch_size, False, gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (4, 32, 32)\n",
      "After:  (4, 32, 32)\n",
      "Mid:    (4, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAACNCAYAAAA5BftnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee07b7c278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAACNCAYAAAA5BftnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee07b7ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAACNCAYAAAA5BftnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvLna1jbhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee80124ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(test_before, test_after), test_mid = sample_train(4)\n",
    "print(\"Before: {}\".format(test_before.shape))\n",
    "print(\"After:  {}\".format(test_after.shape))\n",
    "print(\"Mid:    {}\".format(test_mid.shape))\n",
    "size = (12, 2)\n",
    "plot_images(test_before, size, \"Before\")\n",
    "plot_images(test_mid, size, \"Mid\")\n",
    "plot_images(test_after, size, \"After\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (4, 32, 32)\n",
      "After:  (4, 32, 32)\n",
      "Mid:    (4, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAACNCAYAAAA5BftnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee07b7ceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAACNCAYAAAA5BftnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCABAiuAIAECK4AgAQMr/ADdFspGLyilxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee07b7c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAACNCAYAAAA5BftnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee8005afd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(test_before, test_after), test_mid = sample_dev(4, 11)\n",
    "print(\"Before: {}\".format(test_before.shape))\n",
    "print(\"After:  {}\".format(test_after.shape))\n",
    "print(\"Mid:    {}\".format(test_mid.shape))\n",
    "plot_images(test_before, size, \"Before\")\n",
    "plot_images(test_mid, size, \"Mid\")\n",
    "plot_images(test_after, size, \"After\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def content_loss(x, gd):\n",
    "    x, gd = tf.contrib.layers.flatten(x), tf.contrib.layers.flatten(gd)\n",
    "    return tf.norm(x-gd)\n",
    "\n",
    "\n",
    "def gan_loss(logits_real, logits_fake):\n",
    "    G_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(logits_fake), logits = logits_fake)\n",
    "    \n",
    "    D_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(logits_real), logits = logits_real)\\\n",
    "     +  tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(logits_fake), logits = logits_fake)\n",
    "        \n",
    "    G_loss = tf.reduce_mean(G_loss)\n",
    "    D_loss = tf.reduce_mean(D_loss)\n",
    "    return D_loss, G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(x1, x2,  is_training=True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        x1, x2: batch size of images for inference\n",
    "    Output:\n",
    "        predicted images of batch size\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"generator\"):\n",
    "        # reshape and concatenate\n",
    "        x1 = tf.reshape(x1, [-1,  32, 32, 1])\n",
    "        x2 = tf.reshape(x2, [-1,  32, 32, 1])\n",
    "        x = tf.concat([(x1+x2)/2, (x2-x1)/2], axis=3)\n",
    "        \n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "        x = tf.layers.dense(x, 1024, activation=tf.nn.relu)\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        \n",
    "        x = tf.layers.dense(x, 8*8*128, activation=tf.nn.relu)\n",
    "        x = tf.reshape(x, [-1, 8, 8, 128])\n",
    "        \n",
    "        x = tf.layers.conv2d(x, filters = 32, kernel_size=2, padding='same', activation=tf.nn.relu)\n",
    "        x = tf.layers.batch_normalization(x, axis=3, training=is_training)\n",
    "        \n",
    "        x = tf.layers.conv2d(x, filters = 32, kernel_size=2, padding='same', activation=tf.nn.relu)\n",
    "        x = tf.layers.batch_normalization(x, axis=3, training=is_training)\n",
    "        \n",
    "        \n",
    "\n",
    "        x = tf.layers.conv2d_transpose(x, filters=64, kernel_size=(4, 4), strides=(2, 2), activation=tf.nn.relu, padding='same')\n",
    "        x = tf.layers.batch_normalization(x,  axis=3, training=is_training)\n",
    "        \n",
    "        img = tf.layers.conv2d_transpose(x, filters=1, kernel_size=(4, 4),  strides=(2, 2), activation=tf.nn.tanh, padding='same')\n",
    "        img = tf.reshape(img, [-1, 32, 32, 1])\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_solvers(learning_rate=1e-3, beta1=0.5):\n",
    "    D_solver = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "    G_solver = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "    return D_solver, G_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generattion(before, after, mid):\n",
    "    dic = {batch_before: before, batch_after: after, batch_mid: mid, is_training: False}\n",
    "    gen_batch = sess.run(G_batch, dic)\n",
    "    gen_batch, loss = sess.run([G_batch, G_loss], dic)\n",
    "    return gen_batch, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gap = 1\n",
    "batch_size = 128\n",
    "\n",
    "learning_rate = 1e-4\n",
    "beta = 0.9\n",
    "num_iteration = 3000\n",
    "noise_dim = 128\n",
    "relu_alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_mid        = tf.placeholder(tf.float32, [None, 32, 32])\n",
    "batch_before     = tf.placeholder(tf.float32, [None, 32, 32])\n",
    "batch_after      = tf.placeholder(tf.float32, [None, 32, 32])\n",
    "is_training      = tf.placeholder(tf.bool, ())\n",
    "\n",
    "G_batch = generate(batch_before, batch_after)\n",
    "\n",
    "G_loss = content_loss(G_batch, batch_mid)\n",
    "_, G_solver = get_solvers(learning_rate, beta)\n",
    "\n",
    "G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator') \n",
    "\n",
    "G_train_step = G_solver.minimize(G_loss, var_list=G_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(sess, G_step, G_loss, batch_size, num_iteration, plot_every = 400, show_loss_every=400, nPlot=6):\n",
    "    g_losses = []\n",
    "    for i in range(num_iteration):\n",
    "        (real_before, real_after), real_mid = sample_train(batch_size, gap)\n",
    "        dic = {batch_mid: real_mid, batch_before: real_before, batch_after: real_after, is_training: True}\n",
    "        _, G_loss_curr = sess.run([G_train_step, G_loss], dic)\n",
    "        \n",
    "        g_losses.append(G_loss_curr)\n",
    "        if i%show_loss_every ==0:\n",
    "            print(\"Iteration {}:  G_loss = {}\".format(i, G_loss_curr))\n",
    "            \n",
    "        if i%plot_every == 0:\n",
    "            gen_batch_test = sess.run(G_batch, feed_dict=\\\n",
    "                                      {batch_before: real_before, batch_after: real_after, is_training: False})\n",
    "            plot_batch_images(gen_batch_test[:nPlot], (16, 2) , \"Iteration: {}\".format(i))\n",
    "    return g_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = get_session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "g_loss = train(sess, G_train_step, G_loss, batch_size, num_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize = (8, 2)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(g_loss)\n",
    "plt.title(\"Generator Losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_seen(num=4, gap = 3):\n",
    "    (real_before, real_after), real_mid = sample_train(num, gap)\n",
    "    gen_batch, loss = get_generattion(real_before, real_after, real_mid)\n",
    "    print(\"Loss = {}\".format(loss))\n",
    "    size = (16, 2)\n",
    "    plot_images(real_before, size, \"Before\")\n",
    "    plot_images(real_after, size, \"After\")\n",
    "    plot_images(real_mid, size, \"Mid - Real\")\n",
    "    plot_images(gen_batch, size, \"Mid - Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_seen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_unseens(num = 4, gap = 1):\n",
    "    \"\"\"\n",
    "    randomely sample and test generator\n",
    "    \"\"\"\n",
    "    (real_before, real_after), real_mid = sample_dev(num, gap)\n",
    "    dic = {batch_before: real_before, batch_after: real_after, batch_mid: real_mid, is_training: False}\n",
    "    gen_batch, loss = sess.run([G_batch, G_loss], dic)\n",
    "    print(\"Loss = {}\".format(loss))\n",
    "    size = (16, 2)\n",
    "    plot_images(real_before, size, \"Before\")\n",
    "    plot_images(real_after, size, \"After\")\n",
    "    plot_images(real_mid, size, \"Mid - Real\")\n",
    "    plot_images(gen_batch, size, \"Mid - Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_unseens(gap = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test a total difference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_imgs(imgs, gap = 1, batch_size = 8):\n",
    "    \"\"\"\n",
    "    return: (before, after), mid\n",
    "    \"\"\"\n",
    "    before_indexes = np.random.choice(range(len(imgs) - gap - 1), batch_size, replace=False)\n",
    "    before_indexes.sort()\n",
    "    after_indexes = before_indexes + gap + 1\n",
    "    mid_indexes = (before_indexes + after_indexes)//2\n",
    "    return (imgs[before_indexes], imgs[after_indexes]), imgs[mid_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_imgs = load_imgs(\"data/moving-box/test/rectangle-32x32.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(test_before, test_after), test_mid = sample_imgs(test_imgs, gap = 1)\n",
    "gen_batch, loss = get_generattion(test_before, test_after, test_mid)\n",
    "print(\"Loss = {}\".format(loss))\n",
    "size = (16, 2)\n",
    "plot_images(test_before, size, \"Before\")\n",
    "plot_images(test_after, size, \"After\")\n",
    "plot_images(test_mid, size, \"Mid-Real\")\n",
    "plot_images(gen_batch, size, \"Mid-Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
